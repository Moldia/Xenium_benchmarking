{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "99be5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK FOR BATCH PROCESSING SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac1a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tf\n",
    "from cellpose import models\n",
    "from cellpose import utils\n",
    "from skimage.measure import label, regionprops\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "from skimage.segmentation import expand_labels, watershed\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ecda372",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unsegmented_datasets='../../figures/2.comparison_between_datasets/input_for_segmentation/'\n",
    "datasets=os.listdir(path_unsegmented_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c25b432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CosMx',\n",
       " 'CosMxsegmented_mask.tif',\n",
       " 'HybrISS',\n",
       " 'MERFISH_ABI',\n",
       " 'ResolvedBiosciences',\n",
       " 'Vizgen',\n",
       " 'Xenium']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5392abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COSMX DATASET BREAKS TO SEGMENT\n",
    "## VIZGEN DATASET DOESN'T HAVE A GOOD CORRESPONDANCE TO READS. WE NEED TO APPLY A TRANSFORMATION (MAYBE?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71021b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResolvedBiosciences\n",
      "starting segmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 8456799/8456799 [05:23<00:00, 26152.23it/s]\n",
      "/tmp/ipykernel_3438167/1736721645.py:56: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata=sc.AnnData(cellxgene)\n",
      "/home/sergio/.local/lib/python3.8/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "for ds in datasets[3:4]:\n",
    "    print(ds)\n",
    "    try:\n",
    "        dapi_image = tf.imread(path_unsegmented_datasets+ds+'/DAPI.tif')\n",
    "    except:\n",
    "        dapi_image = tf.imread(path_unsegmented_datasets+ds+'/DAPI.tiff')\n",
    "    read_positions = pd.read_csv(path_unsegmented_datasets+ds+'/transcripts.csv',index_col=0)\n",
    "    if ds=='CosMx':\n",
    "        read_positions['x']=read_positions['y_global_px']\n",
    "        read_positions['y']=read_positions['x_global_px']\n",
    "        read_positions['x']=read_positions['x']-np.min(read_positions['x'])\n",
    "        read_positions['y']=read_positions['y']-np.min(read_positions['y'])\n",
    "    if ds in ['MERFISH_ABI']:\n",
    "        read_positions['x']=(read_positions['x_um']-read_positions['x_um'].min())*9.20586\n",
    "        read_positions['y']=(read_positions['y_um']-read_positions['y_um'].min())*9.20586\n",
    "    if ds in ['Vizgen']:\n",
    "        read_positions['x']=read_positions['global_x']*9.20586\n",
    "        read_positions['y']=read_positions['global_y']*9.20586\n",
    "    if ds in ['Xenium']:\n",
    "        read_positions['x']=read_positions['x']*4.70588\n",
    "        read_positions['y']=read_positions['y']*4.70588\n",
    "    #plt.figure(figsize=(7,7))\n",
    "    #plt.imshow(dapi_image,vmax=1200)\n",
    "    #plt.scatter(read_positions['x'],read_positions['y'],s=0.001,c='red')\n",
    "   \n",
    "    # Initialize Cellpose model for nuclei segmentation\n",
    "    model = models.Cellpose(gpu=False, model_type='nuclei')\n",
    "    # Segment nuclei\n",
    "    print('starting segmentation...')\n",
    "    masks, flows, styles, diams = model.eval(dapi_image, diameter=None, channels=[0, 0])\n",
    "    # Label the segmented nuclei\n",
    "    labeled_nuclei = label(masks)\n",
    "    expanded_nuclei = expand_labels(labeled_nuclei, distance=400)\n",
    "    from skimage.color import label2rgb\n",
    "    color1 = label2rgb(expanded_nuclei, bg_label=0)\n",
    "    plt.imshow(color1)\n",
    "    centroid_dictx={}\n",
    "    centroid_dicty={}\n",
    "    for nucleus_props in regionprops(labeled_nuclei):\n",
    "        centroid_dictx[nucleus_props.label]=nucleus_props.centroid[0]\n",
    "        centroid_dicty[nucleus_props.label]=nucleus_props.centroid[1]\n",
    "    closest_cell=[]\n",
    "    in_cell=[]\n",
    "    for ind in tqdm(read_positions.index):\n",
    "        try:\n",
    "            in_cell.append(labeled_nuclei[read_positions.loc[ind,'x'],read_positions.loc[ind,'y']])\n",
    "            closest_cell.append(expanded_nuclei[read_positions.loc[ind,'x'],read_positions.loc[ind,'y']])\n",
    "        except:\n",
    "            in_cell.append(0)\n",
    "            closest_cell.append(0)\n",
    "    read_positions['in_cell']=in_cell\n",
    "    read_positions['closest_cell']=closest_cell\n",
    "    read_positions['closest_cell_x']=read_positions['closest_cell'].map(centroid_dictx)\n",
    "    read_positions['closest_cell_y']=read_positions['closest_cell'].map(centroid_dicty)\n",
    "    read_positions['distance_to_centroid']=np.sqrt((read_positions['closest_cell_y']-read_positions['y'])**2 +(read_positions['closest_cell_x']-read_positions['x'])**2)\n",
    "    cellxgene=pd.crosstab(read_positions['in_cell'],read_positions['gene'])\n",
    "    cellxgene=cellxgene.loc[~cellxgene.index.isin([0]),:]\n",
    "    import scanpy as sc\n",
    "    adata=sc.AnnData(cellxgene)\n",
    "    adata.obs['x_centroid']=adata.obs.index.astype(int).map(centroid_dictx)\n",
    "    adata.obs['y_centroid']=adata.obs.index.astype(int).map(centroid_dicty)\n",
    "    adata.write(path_unsegmented_datasets+ds+'/adata.h5ad')\n",
    "    read_positions.to_csv(path_unsegmented_datasets+ds+'/transcripts_with_cell_assignment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061f37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xenium\n",
      "starting segmentation...\n"
     ]
    }
   ],
   "source": [
    "for ds in datasets[5:6]:\n",
    "    print(ds)\n",
    "    try:\n",
    "        dapi_image = tf.imread(path_unsegmented_datasets+ds+'/DAPI.tif')\n",
    "    except:\n",
    "        dapi_image = tf.imread(path_unsegmented_datasets+ds+'/DAPI.tiff')\n",
    "    read_positions = pd.read_csv(path_unsegmented_datasets+ds+'/transcripts.csv',index_col=0)\n",
    "    if ds=='CosMx':\n",
    "        read_positions['x']=read_positions['y_global_px']\n",
    "        read_positions['y']=read_positions['x_global_px']\n",
    "        read_positions['x']=read_positions['x']-np.min(read_positions['x'])\n",
    "        read_positions['y']=read_positions['y']-np.min(read_positions['y'])\n",
    "    if ds in ['MERFISH_ABI']:\n",
    "        read_positions['x']=(read_positions['x_um']-read_positions['x_um'].min())*9.20586\n",
    "        read_positions['y']=(read_positions['y_um']-read_positions['y_um'].min())*9.20586\n",
    "    if ds in ['Vizgen']:\n",
    "        read_positions['x']=read_positions['global_x']*9.20586\n",
    "        read_positions['y']=read_positions['global_y']*9.20586\n",
    "    if ds in ['Xenium']:\n",
    "        read_positions['x']=read_positions['x']*4.70588\n",
    "        read_positions['y']=read_positions['y']*4.70588\n",
    "    #plt.figure(figsize=(7,7))\n",
    "    #plt.imshow(dapi_image,vmax=1200)\n",
    "    #plt.scatter(read_positions['x'],read_positions['y'],s=0.001,c='red')\n",
    "   \n",
    "    # Initialize Cellpose model for nuclei segmentation\n",
    "    model = models.Cellpose(gpu=False, model_type='nuclei')\n",
    "    # Segment nuclei\n",
    "    print('starting segmentation...')\n",
    "    masks, flows, styles, diams = model.eval(dapi_image, diameter=None, channels=[0, 0])\n",
    "    # Label the segmented nuclei\n",
    "    labeled_nuclei = label(masks)\n",
    "    expanded_nuclei = expand_labels(labeled_nuclei, distance=400)\n",
    "    from skimage.color import label2rgb\n",
    "    color1 = label2rgb(expanded_nuclei, bg_label=0)\n",
    "    plt.imshow(color1)\n",
    "    centroid_dictx={}\n",
    "    centroid_dicty={}\n",
    "    for nucleus_props in regionprops(labeled_nuclei):\n",
    "        centroid_dictx[nucleus_props.label]=nucleus_props.centroid[0]\n",
    "        centroid_dicty[nucleus_props.label]=nucleus_props.centroid[1]\n",
    "    closest_cell=[]\n",
    "    in_cell=[]\n",
    "    for ind in tqdm(read_positions.index):\n",
    "        try:\n",
    "            in_cell.append(labeled_nuclei[read_positions.loc[ind,'x'],read_positions.loc[ind,'y']])\n",
    "            closest_cell.append(expanded_nuclei[read_positions.loc[ind,'x'],read_positions.loc[ind,'y']])\n",
    "        except:\n",
    "            in_cell.append(0)\n",
    "            closest_cell.append(0)\n",
    "    read_positions['in_cell']=in_cell\n",
    "    read_positions['closest_cell']=closest_cell\n",
    "    read_positions['closest_cell_x']=read_positions['closest_cell'].map(centroid_dictx)\n",
    "    read_positions['closest_cell_y']=read_positions['closest_cell'].map(centroid_dicty)\n",
    "    read_positions['distance_to_centroid']=np.sqrt((read_positions['closest_cell_y']-read_positions['y'])**2 +(read_positions['closest_cell_x']-read_positions['x'])**2)\n",
    "    cellxgene=pd.crosstab(read_positions['in_cell'],read_positions['gene'])\n",
    "    cellxgene=cellxgene.loc[~cellxgene.index.isin([0]),:]\n",
    "    import scanpy as sc\n",
    "    adata=sc.AnnData(cellxgene)\n",
    "    adata.obs['x_centroid']=adata.obs.index.astype(int).map(centroid_dictx)\n",
    "    adata.obs['y_centroid']=adata.obs.index.astype(int).map(centroid_dicty)\n",
    "    adata.write(path_unsegmented_datasets+ds+'/adata.h5ad')\n",
    "    read_positions.to_csv(path_unsegmented_datasets+ds+'/transcripts_with_cell_assignment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c04935",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds='Xenium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8f5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dapi_image = tf.imread(path_unsegmented_datasets+ds+'/DAPI.tiff')\n",
    "tile_size=[2000,2000]\n",
    "overlap=100\n",
    "tile_positions = []\n",
    "segmented_masks = []\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c55ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_positions = pd.read_csv(path_unsegmented_datasets+ds+'/transcripts.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aaaba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_positions['x']=read_positions['y_global_px']\n",
    "read_positions['y']=read_positions['x_global_px']\n",
    "read_positions['x']=read_positions['x']-np.min(read_positions['x'])\n",
    "read_positions['y']=read_positions['y']-np.min(read_positions['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c4ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/18 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/26 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "height, width = dapi_image.shape[:2]\n",
    "\n",
    "for y in tqdm(range(0, height, tile_size[1] - overlap)):\n",
    "    for x in tqdm(range(0, width, tile_size[0] - overlap)):\n",
    "        # Calculate tile boundaries\n",
    "        x1, x2 = x, min(x + tile_size[0], width)\n",
    "        y1, y2 = y, min(y + tile_size[1], height)\n",
    "\n",
    "        # Extract the tile\n",
    "        tile = dapi_image[y1:y2, x1:x2]\n",
    "\n",
    "        # Store the tile position\n",
    "        tile_positions.append((x1, y1))\n",
    "\n",
    "        # Step 2: Segment each tile with Cellpose\n",
    "        # Initialize Cellpose model\n",
    "        model = models.Cellpose(gpu=False)  # You can set GPU to True if available\n",
    "\n",
    "        # Run Cellpose on each tile\n",
    "        masks, _, _, _ = model.eval(tile, channels=[0, 0], diameter=None)  # Modify channels and diameter as needed\n",
    "        \n",
    "        segmented_masks.append(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Recompose the segmented masks into a single mask\n",
    "full_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "for mask, position in tqdm(zip(segmented_masks, tile_positions)):\n",
    "    x, y = position\n",
    "    h, w = mask.shape[:2]\n",
    "    full_mask[y:y + h, x:x + w] = mask # Assuming you want only one channel of the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(full_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074907a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save the full mask to a file\n",
    "tf.imwrite(path_unsegmented_datasets+ds+\"/segmented_mask.tif\", full_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701735ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_global_px</th>\n",
       "      <th>y_global_px</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-494466.803333</td>\n",
       "      <td>9108.900</td>\n",
       "      <td>Gfap</td>\n",
       "      <td>39522.820</td>\n",
       "      <td>3903.496667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-494237.833333</td>\n",
       "      <td>10084.600</td>\n",
       "      <td>Ngf</td>\n",
       "      <td>40498.520</td>\n",
       "      <td>4132.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-494239.533333</td>\n",
       "      <td>10080.917</td>\n",
       "      <td>Igfbp7</td>\n",
       "      <td>40494.837</td>\n",
       "      <td>4130.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-494227.493333</td>\n",
       "      <td>10072.143</td>\n",
       "      <td>Gnaq</td>\n",
       "      <td>40486.063</td>\n",
       "      <td>4142.806667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-494219.603333</td>\n",
       "      <td>10065.550</td>\n",
       "      <td>Cldn5</td>\n",
       "      <td>40479.470</td>\n",
       "      <td>4150.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116159822</th>\n",
       "      <td>-454293.000000</td>\n",
       "      <td>-22302.590</td>\n",
       "      <td>Apoe</td>\n",
       "      <td>8111.330</td>\n",
       "      <td>44077.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116159823</th>\n",
       "      <td>-454296.300000</td>\n",
       "      <td>-22325.660</td>\n",
       "      <td>Prkacb</td>\n",
       "      <td>8088.260</td>\n",
       "      <td>44074.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116159824</th>\n",
       "      <td>-454262.000000</td>\n",
       "      <td>-22325.610</td>\n",
       "      <td>Cox6c</td>\n",
       "      <td>8088.310</td>\n",
       "      <td>44108.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116159825</th>\n",
       "      <td>-454297.800000</td>\n",
       "      <td>-22326.310</td>\n",
       "      <td>Malat1</td>\n",
       "      <td>8087.610</td>\n",
       "      <td>44072.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116159826</th>\n",
       "      <td>-454287.000000</td>\n",
       "      <td>-22326.330</td>\n",
       "      <td>Rab6a</td>\n",
       "      <td>8087.590</td>\n",
       "      <td>44083.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116159827 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_global_px  y_global_px  target          x             y\n",
       "0         -494466.803333     9108.900    Gfap  39522.820   3903.496667\n",
       "1         -494237.833333    10084.600     Ngf  40498.520   4132.466667\n",
       "2         -494239.533333    10080.917  Igfbp7  40494.837   4130.766667\n",
       "3         -494227.493333    10072.143    Gnaq  40486.063   4142.806667\n",
       "4         -494219.603333    10065.550   Cldn5  40479.470   4150.696667\n",
       "...                  ...          ...     ...        ...           ...\n",
       "116159822 -454293.000000   -22302.590    Apoe   8111.330  44077.300000\n",
       "116159823 -454296.300000   -22325.660  Prkacb   8088.260  44074.000000\n",
       "116159824 -454262.000000   -22325.610   Cox6c   8088.310  44108.300000\n",
       "116159825 -454297.800000   -22326.310  Malat1   8087.610  44072.500000\n",
       "116159826 -454287.000000   -22326.330   Rab6a   8087.590  44083.300000\n",
       "\n",
       "[116159827 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b044ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final mask (for visualization purposes)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(full_mask,vmax=1)\n",
    "plt.scatter(read_positions.x,read_positions.y,s=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_nuclei = label(masks)\n",
    "expanded_nuclei = expand_labels(labeled_nuclei, distance=400)\n",
    "from skimage.color import label2rgb\n",
    "color1 = label2rgb(expanded_nuclei, bg_label=0)\n",
    "plt.imshow(color1)\n",
    "centroid_dictx={}\n",
    "centroid_dicty={}\n",
    "for nucleus_props in regionprops(labeled_nuclei):\n",
    "    centroid_dictx[nucleus_props.label]=nucleus_props.centroid[0]\n",
    "    centroid_dicty[nucleus_props.label]=nucleus_props.centroid[1]\n",
    "closest_cell=[]\n",
    "in_cell=[]\n",
    "for ind in tqdm(read_positions.index):\n",
    "    try:\n",
    "        in_cell.append(labeled_nuclei[read_positions.loc[ind,'x'],read_positions.loc[ind,'y']])\n",
    "        closest_cell.append(expanded_nuclei[read_positions.loc[ind,'x'],read_positions.loc[ind,'y']])\n",
    "    except:\n",
    "        in_cell.append(0)\n",
    "        closest_cell.append(0)\n",
    "read_positions['in_cell']=in_cell\n",
    "read_positions['closest_cell']=closest_cell\n",
    "read_positions['closest_cell_x']=read_positions['closest_cell'].map(centroid_dictx)\n",
    "read_positions['closest_cell_y']=read_positions['closest_cell'].map(centroid_dicty)\n",
    "read_positions['distance_to_centroid']=np.sqrt((read_positions['closest_cell_y']-read_positions['y'])**2 +(read_positions['closest_cell_x']-read_positions['x'])**2)\n",
    "cellxgene=pd.crosstab(read_positions['in_cell'],read_positions['gene'])\n",
    "cellxgene=cellxgene.loc[~cellxgene.index.isin([0]),:]\n",
    "import scanpy as sc\n",
    "adata=sc.AnnData(cellxgene)\n",
    "adata.obs['x_centroid']=adata.obs.index.astype(int).map(centroid_dictx)\n",
    "adata.obs['y_centroid']=adata.obs.index.astype(int).map(centroid_dicty)\n",
    "adata.write(path_unsegmented_datasets+ds+'/adata.h5ad')\n",
    "read_positions.to_csv(path_unsegmented_datasets+ds+'/transcripts_with_cell_assignment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6455baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 2: Segment each tile with Cellpose\n",
    "segmented_masks = []\n",
    "\n",
    "# Initialize Cellpose model\n",
    "model = models.Cellpose(gpu=False)  # You can set GPU to True if available\n",
    "\n",
    "for tile in tiles:\n",
    "    # Run Cellpose on each tile\n",
    "    masks, _, _, _ = model.eval(tile, channels=[0, 0], diameter=30)  # Modify channels and diameter as needed\n",
    "    segmented_masks.append(masks)\n",
    "\n",
    "# Step 3: Recompose the segmented masks into a single mask\n",
    "original_image_shape = large_image.shape[:2]\n",
    "\n",
    "full_mask = np.zeros(original_image_shape, dtype=np.uint8)\n",
    "\n",
    "for mask, position in zip(segmented_masks, tile_positions):\n",
    "    x, y = position\n",
    "    h, w = mask.shape[:2]\n",
    "    full_mask[y:y + h, x:x + w] = mask[..., 0]  # Assuming you want only one channel of the mask\n",
    "\n",
    "# 'full_mask' now contains the segmentation mask for the entire image\n",
    "\n",
    "# Optional: Save the full mask to a file\n",
    "cv2.imwrite(\"segmented_mask.jpg\", full_mask)\n",
    "\n",
    "# Optional: Perform post-processing on the 'full_mask' if needed\n",
    "\n",
    "# Display the final mask (for visualization purposes)\n",
    "cv2.imshow(\"Segmented Mask\", full_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13340b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'segmented_masks' is a list of segmented masks for each tile\n",
    "# and 'tile_positions' is a list of the positions of each tile in the original image\n",
    "\n",
    "# Determine the shape of the original image\n",
    "original_image_shape = (height, width)\n",
    "\n",
    "# Create an empty mask of the same shape as the original image\n",
    "full_mask = np.zeros(original_image_shape, dtype=np.uint8)\n",
    "\n",
    "# Iterate through the segmented masks and tile positions\n",
    "for mask, position in zip(segmented_masks, tile_positions):\n",
    "    x, y = position  # Position of the top-left corner of the tile\n",
    "    h, w = mask.shape  # Height and width of the tile\n",
    "    full_mask[y:y + h, x:x + w] = mask\n",
    "\n",
    "# 'full_mask' now contains the segmentation mask for the entire image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef368720",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=['CosMx','Vizgen','Xenium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1a78f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybrISS\n",
      "MERFISH_ABI\n",
      "ResolvedBiosciences\n"
     ]
    }
   ],
   "source": [
    "for ds in datasets:\n",
    "    if os.path.exists(path_unsegmented_datasets+ds+'/transcripts_with_cell_assignment.csv'):\n",
    "        print(ds)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
